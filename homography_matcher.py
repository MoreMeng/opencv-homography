#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenCV Homography Matcher
‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏û Eye-Level ‡∏Å‡∏±‡∏ö Top-Down ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Feature Matching + Homography

Author: Your Name
Date: 2025-07-25
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import argparse
import os
from typing import Tuple, Optional


class HomographyMatcher:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ Feature Matching ‡πÅ‡∏•‡∏∞ Homography Transformation
    """

    def __init__(self, feature_detector='SIFT', min_match_count=10):
        """
        Initialize the HomographyMatcher

        Args:
            feature_detector (str): ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á feature detector ('SIFT', 'ORB', 'AKAZE')
            min_match_count (int): ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        """
        self.min_match_count = min_match_count
        self.feature_detector = feature_detector

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á feature detector ‡πÅ‡∏•‡∏∞ matcher
        if feature_detector == 'SIFT':
            self.detector = cv2.SIFT_create()
            # FLANN matcher ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SIFT
            FLANN_INDEX_KDTREE = 1
            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
            search_params = dict(checks=50)
            self.matcher = cv2.FlannBasedMatcher(index_params, search_params)
        elif feature_detector == 'ORB':
            self.detector = cv2.ORB_create()
            # BFMatcher ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ORB
            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        elif feature_detector == 'AKAZE':
            self.detector = cv2.AKAZE_create()
            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        else:
            raise ValueError(f"Unsupported feature detector: {feature_detector}")

    def load_and_preprocess_image(self, image_path: str) -> np.ndarray:
        """
        ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏†‡∏≤‡∏û

        Args:
            image_path (str): path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û

        Returns:
            np.ndarray: ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û: {image_path}")

        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ: {image_path}")

        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # ‡∏õ‡∏£‡∏±‡∏ö contrast ‡πÅ‡∏•‡∏∞ brightness
        gray = cv2.convertScaleAbs(gray, alpha=1.2, beta=10)

        return img, gray

    def detect_and_compute_features(self, gray_img: np.ndarray) -> Tuple[list, np.ndarray]:
        """
        ‡∏´‡∏≤ keypoints ‡πÅ‡∏•‡∏∞ descriptors ‡πÉ‡∏ô‡∏†‡∏≤‡∏û

        Args:
            gray_img (np.ndarray): ‡∏†‡∏≤‡∏û grayscale

        Returns:
            Tuple[list, np.ndarray]: keypoints ‡πÅ‡∏•‡∏∞ descriptors
        """
        keypoints, descriptors = self.detector.detectAndCompute(gray_img, None)
        return keypoints, descriptors

    def match_features(self, desc1: np.ndarray, desc2: np.ndarray) -> list:
        """
        ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà features ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏û

        Args:
            desc1 (np.ndarray): descriptors ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏£‡∏Å
            desc2 (np.ndarray): descriptors ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á

        Returns:
            list: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á good matches
        """
        if desc1 is None or desc2 is None:
            return []

        if self.feature_detector == 'SIFT':
            # ‡πÉ‡∏ä‡πâ FLANN matcher ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SIFT
            matches = self.matcher.knnMatch(desc1, desc2, k=2)

            # Apply Lowe's ratio test
            good_matches = []
            for match_pair in matches:
                if len(match_pair) == 2:
                    m, n = match_pair
                    if m.distance < 0.7 * n.distance:
                        good_matches.append(m)
        else:
            # ‡πÉ‡∏ä‡πâ BFMatcher ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ORB ‡πÅ‡∏•‡∏∞ AKAZE
            matches = self.matcher.match(desc1, desc2)
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° distance
            matches = sorted(matches, key=lambda x: x.distance)
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ matches ‡∏ó‡∏µ‡πà‡∏î‡∏µ (25% ‡πÅ‡∏£‡∏Å)
            good_matches = matches[:len(matches)//4]

        return good_matches

    def find_homography(self, kp1: list, kp2: list, matches: list) -> Optional[np.ndarray]:
        """
        ‡∏´‡∏≤ Homography matrix ‡∏à‡∏≤‡∏Å matched keypoints

        Args:
            kp1 (list): keypoints ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏£‡∏Å
            kp2 (list): keypoints ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á
            matches (list): ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á good matches

        Returns:
            Optional[np.ndarray]: Homography matrix ‡∏´‡∏£‡∏∑‡∏≠ None
        """
        if len(matches) < self.min_match_count:
            print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô matches ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠: {len(matches)}/{self.min_match_count}")
            return None

        # ‡πÅ‡∏¢‡∏Å coordinates ‡∏Ç‡∏≠‡∏á matched points
        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

        # ‡∏´‡∏≤ Homography matrix ‡∏î‡πâ‡∏ß‡∏¢ RANSAC
        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

        return H, mask

    def transform_image(self, img: np.ndarray, H: np.ndarray, target_shape: Tuple[int, int]) -> np.ndarray:
        """
        Transform ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ Homography matrix

        Args:
            img (np.ndarray): ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            H (np.ndarray): Homography matrix
            target_shape (Tuple[int, int]): ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (width, height)

        Returns:
            np.ndarray: ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å transform ‡πÅ‡∏•‡πâ‡∏ß
        """
        return cv2.warpPerspective(img, H, target_shape)

    def visualize_matches(self, img1: np.ndarray, kp1: list, img2: np.ndarray, kp2: list,
                         matches: list, H: Optional[np.ndarray] = None) -> np.ndarray:
        """
        ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà features

        Args:
            img1, img2: ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            kp1, kp2: keypoints
            matches: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á matches
            H: Homography matrix (optional)

        Returns:
            np.ndarray: ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• matches
        draw_params = dict(matchColor=(0, 255, 0),    # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö matches
                          singlePointColor=None,
                          matchesMask=None,           # ‡∏ß‡∏≤‡∏î‡∏ó‡∏∏‡∏Å matches
                          flags=2)

        img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, **draw_params)

        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Homography ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
        if H is not None:
            h, w = img1.shape[:2]
            pts = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)
            dst = cv2.perspectiveTransform(pts, H)

            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á
            img2_with_box = img2.copy()
            cv2.polylines(img2_with_box, [np.int32(dst)], True, (0, 0, 255), 3, cv2.LINE_AA)

            # ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û
            img_matches = cv2.drawMatches(img1, kp1, img2_with_box, kp2, matches, None, **draw_params)

        return img_matches

    def compare_images(self, eye_level_path: str, top_down_path: str,
                      output_dir: str = "output") -> dict:
        """
        ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏û Eye-Level ‡∏Å‡∏±‡∏ö Top-Down

        Args:
            eye_level_path (str): path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û eye-level
            top_down_path (str): path ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û top-down
            output_dir (str): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

        Returns:
            dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        os.makedirs(output_dir, exist_ok=True)

        print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏†‡∏≤‡∏û...")

        # ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û
        img1, gray1 = self.load_and_preprocess_image(eye_level_path)
        img2, gray2 = self.load_and_preprocess_image(top_down_path)

        print(f"üìè ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û Eye-Level: {img1.shape}")
        print(f"üìè ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û Top-Down: {img2.shape}")

        # ‡∏´‡∏≤ features
        print(f"üîé ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤ features ‡∏î‡πâ‡∏ß‡∏¢ {self.feature_detector}...")
        kp1, desc1 = self.detect_and_compute_features(gray1)
        kp2, desc2 = self.detect_and_compute_features(gray2)

        print(f"‚úÖ ‡∏û‡∏ö keypoints ‡πÉ‡∏ô‡∏†‡∏≤‡∏û Eye-Level: {len(kp1)}")
        print(f"‚úÖ ‡∏û‡∏ö keypoints ‡πÉ‡∏ô‡∏†‡∏≤‡∏û Top-Down: {len(kp2)}")

        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà features
        print("üîó ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà features...")
        matches = self.match_features(desc1, desc2)
        print(f"‚úÖ ‡∏û‡∏ö good matches: {len(matches)}")

        results = {
            'eye_level_keypoints': len(kp1),
            'top_down_keypoints': len(kp2),
            'total_matches': len(matches),
            'homography_found': False,
            'confidence_score': 0.0
        }

        if len(matches) >= self.min_match_count:
            # ‡∏´‡∏≤ Homography
            print("üìê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography matrix...")
            homography_result = self.find_homography(kp1, kp2, matches)

            if homography_result is not None:
                H, mask = homography_result
                matches_mask = mask.ravel().tolist()
                inlier_matches = [m for i, m in enumerate(matches) if matches_mask[i]]

                results['homography_found'] = True
                results['inlier_matches'] = len(inlier_matches)
                results['confidence_score'] = len(inlier_matches) / len(matches)

                print(f"‚úÖ ‡∏û‡∏ö Homography! Inlier matches: {len(inlier_matches)}/{len(matches)}")
                print(f"üìä Confidence Score: {results['confidence_score']:.2f}")

                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
                img_matches = self.visualize_matches(img1, kp1, img2, kp2, inlier_matches, H)

                # Transform ‡∏†‡∏≤‡∏û eye-level ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô top-down view
                h, w = img2.shape[:2]
                transformed_img = self.transform_image(img1, H, (w, h))

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                cv2.imwrite(os.path.join(output_dir, "matches_visualization.jpg"), img_matches)
                cv2.imwrite(os.path.join(output_dir, "transformed_eye_level.jpg"), transformed_img)
                cv2.imwrite(os.path.join(output_dir, "original_top_down.jpg"), img2)

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡∏Å‡∏±‡∏ô
                comparison = np.hstack((transformed_img, img2))
                cv2.imwrite(os.path.join(output_dir, "comparison.jpg"), comparison)

                print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {output_dir}")

            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤ Homography ‡πÑ‡∏î‡πâ")
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• matches ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                img_matches = self.visualize_matches(img1, kp1, img2, kp2, matches[:50])  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 50 matches ‡πÅ‡∏£‡∏Å
                cv2.imwrite(os.path.join(output_dir, "failed_matches.jpg"), img_matches)
        else:
            print(f"‚ùå ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô matches ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤ Homography ({len(matches)}/{self.min_match_count})")
            if len(matches) > 0:
                img_matches = self.visualize_matches(img1, kp1, img2, kp2, matches)
                cv2.imwrite(os.path.join(output_dir, "insufficient_matches.jpg"), img_matches)

        return results


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°"""
    parser = argparse.ArgumentParser(description='OpenCV Homography Matcher')
    parser.add_argument('--eye_level', required=True, help='Path to eye-level image')
    parser.add_argument('--top_down', required=True, help='Path to top-down image')
    parser.add_argument('--detector', default='SIFT', choices=['SIFT', 'ORB', 'AKAZE'],
                       help='Feature detector to use')
    parser.add_argument('--min_matches', type=int, default=10,
                       help='Minimum number of matches required')
    parser.add_argument('--output', default='output', help='Output directory')

    args = parser.parse_args()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á matcher
    matcher = HomographyMatcher(
        feature_detector=args.detector,
        min_match_count=args.min_matches
    )

    try:
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏û
        results = matcher.compare_images(
            args.eye_level,
            args.top_down,
            args.output
        )

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ
        print("\n" + "="*50)
        print("üìã ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
        print("="*50)
        print(f"Eye-Level Keypoints: {results['eye_level_keypoints']}")
        print(f"Top-Down Keypoints: {results['top_down_keypoints']}")
        print(f"Total Matches: {results['total_matches']}")

        if results['homography_found']:
            print(f"Inlier Matches: {results['inlier_matches']}")
            print(f"Confidence Score: {results['confidence_score']:.2f}")
            print("‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á")

    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
